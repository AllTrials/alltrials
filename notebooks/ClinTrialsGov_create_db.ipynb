{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the local DB and csv file with all trials data\n",
    "This notebooks shows how to create static copies of CLinicalTrials.goc databases from manually downloaded json clinical trial records.\n",
    "The created sqlite database and csv file can be later used in the analysis pipelines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import json\n",
    "import sqlite3\n",
    "from typing import Any\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download all records locally\n",
    "While not the most efficient, due to clinicaltrials.gov API limitations (max 1000 records per query), this might be the best way to proceed\n",
    "So.. first we need to download the full dataset from: \n",
    "    \n",
    "    https://classic.clinicaltrials.gov/api/gui/ref/download_all\n",
    "\n",
    "We chose the JSON download format:\n",
    "    https://classic.clinicaltrials.gov/AllAPIJSON.zip\n",
    "## Check what study fields are avaialble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-19 21:08:52 - Start\n",
      "['Acronym', 'AgreementOtherDetails', 'AgreementPISponsorEmployee', 'AgreementRestrictionType', 'AgreementRestrictiveAgreement', 'ArmGroupDescription', 'ArmGroupInterventionName', 'ArmGroupLabel', 'ArmGroupType', 'AvailIPDComment', 'AvailIPDId', 'AvailIPDType', 'AvailIPDURL', 'BaselineCategoryTitle', 'BaselineClassDenomCountGroupId', 'BaselineClassDenomCountValue', 'BaselineClassDenomUnits', 'BaselineClassTitle', 'BaselineDenomCountGroupId', 'BaselineDenomCountValue', 'BaselineDenomUnits', 'BaselineGroupDescription', 'BaselineGroupId', 'BaselineGroupTitle', 'BaselineMeasureCalculatePct', 'BaselineMeasureDenomCountGroupId', 'BaselineMeasureDenomCountValue', 'BaselineMeasureDenomUnits', 'BaselineMeasureDenomUnitsSelected', 'BaselineMeasureDescription', 'BaselineMeasureDispersionType', 'BaselineMeasureParamType', 'BaselineMeasurePopulationDescription', 'BaselineMeasureTitle', 'BaselineMeasureUnitOfMeasure', 'BaselineMeasurementComment', 'BaselineMeasurementGroupId', 'BaselineMeasurementLowerLimit', 'BaselineMeasurementSpread', 'BaselineMeasurementUpperLimit', 'BaselineMeasurementValue', 'BaselinePopulationDescription', 'BaselineTypeUnitsAnalyzed', 'BioSpecDescription', 'BioSpecRetention', 'BriefSummary', 'BriefTitle', 'CentralContactEMail', 'CentralContactName', 'CentralContactPhone', 'CentralContactPhoneExt', 'CentralContactRole', 'CollaboratorClass', 'CollaboratorName', 'CompletionDate', 'CompletionDateType', 'Condition', 'ConditionAncestorId', 'ConditionAncestorTerm', 'ConditionBrowseBranchAbbrev', 'ConditionBrowseBranchName', 'ConditionBrowseLeafAsFound', 'ConditionBrowseLeafId', 'ConditionBrowseLeafName', 'ConditionBrowseLeafRelevance', 'ConditionMeshId', 'ConditionMeshTerm', 'DelayedPosting', 'DesignAllocation', 'DesignInterventionModel', 'DesignInterventionModelDescription', 'DesignMasking', 'DesignMaskingDescription', 'DesignObservationalModel', 'DesignPrimaryPurpose', 'DesignTimePerspective', 'DesignWhoMasked', 'DetailedDescription', 'DispFirstPostDate', 'DispFirstPostDateType', 'DispFirstSubmitDate', 'DispFirstSubmitQCDate', 'EligibilityCriteria', 'EnrollmentCount', 'EnrollmentType', 'EventGroupDeathsNumAffected', 'EventGroupDeathsNumAtRisk', 'EventGroupDescription', 'EventGroupId', 'EventGroupOtherNumAffected', 'EventGroupOtherNumAtRisk', 'EventGroupSeriousNumAffected', 'EventGroupSeriousNumAtRisk', 'EventGroupTitle', 'EventsDescription', 'EventsFrequencyThreshold', 'EventsTimeFrame', 'ExpAccTypeIndividual', 'ExpAccTypeIntermediate', 'ExpAccTypeTreatment', 'ExpandedAccessNCTId', 'ExpandedAccessStatusForNCTId', 'FDAAA801Violation', 'FlowAchievementComment', 'FlowAchievementGroupId', 'FlowAchievementNumSubjects', 'FlowAchievementNumUnits', 'FlowDropWithdrawComment', 'FlowDropWithdrawType', 'FlowGroupDescription', 'FlowGroupId', 'FlowGroupTitle', 'FlowMilestoneComment', 'FlowMilestoneType', 'FlowPeriodTitle', 'FlowPreAssignmentDetails', 'FlowReasonComment', 'FlowReasonGroupId', 'FlowReasonNumSubjects', 'FlowReasonNumUnits', 'FlowRecruitmentDetails', 'FlowTypeUnitsAnalyzed', 'Gender', 'GenderBased', 'GenderDescription', 'HasExpandedAccess', 'HealthyVolunteers', 'IPDSharing', 'IPDSharingAccessCriteria', 'IPDSharingDescription', 'IPDSharingInfoType', 'IPDSharingTimeFrame', 'IPDSharingURL', 'InterventionAncestorId', 'InterventionAncestorTerm', 'InterventionArmGroupLabel', 'InterventionBrowseBranchAbbrev', 'InterventionBrowseBranchName', 'InterventionBrowseLeafAsFound', 'InterventionBrowseLeafId', 'InterventionBrowseLeafName', 'InterventionBrowseLeafRelevance', 'InterventionDescription', 'InterventionMeshId', 'InterventionMeshTerm', 'InterventionName', 'InterventionOtherName', 'InterventionType', 'IsFDARegulatedDevice', 'IsFDARegulatedDrug', 'IsPPSD', 'IsUSExport', 'IsUnapprovedDevice', 'Keyword', 'LargeDocDate', 'LargeDocFilename', 'LargeDocHasICF', 'LargeDocHasProtocol', 'LargeDocHasSAP', 'LargeDocLabel', 'LargeDocTypeAbbrev', 'LargeDocUploadDate', 'LastKnownStatus', 'LastUpdatePostDate', 'LastUpdatePostDateType', 'LastUpdateSubmitDate', 'LeadSponsorClass', 'LeadSponsorName', 'LimitationsAndCaveatsDescription', 'LocationCity', 'LocationContactEMail', 'LocationContactName', 'LocationContactPhone', 'LocationContactPhoneExt', 'LocationContactRole', 'LocationCountry', 'LocationFacility', 'LocationState', 'LocationStatus', 'LocationZip', 'MaximumAge', 'MinimumAge', 'NCTId', 'NCTIdAlias', 'OfficialTitle', 'OrgClass', 'OrgFullName', 'OrgStudyId', 'OrgStudyIdDomain', 'OrgStudyIdLink', 'OrgStudyIdType', 'OtherEventAssessmentType', 'OtherEventNotes', 'OtherEventOrganSystem', 'OtherEventSourceVocabulary', 'OtherEventStatsGroupId', 'OtherEventStatsNumAffected', 'OtherEventStatsNumAtRisk', 'OtherEventStatsNumEvents', 'OtherEventTerm', 'OtherOutcomeDescription', 'OtherOutcomeMeasure', 'OtherOutcomeTimeFrame', 'OutcomeAnalysisCILowerLimit', 'OutcomeAnalysisCILowerLimitComment', 'OutcomeAnalysisCINumSides', 'OutcomeAnalysisCIPctValue', 'OutcomeAnalysisCIUpperLimit', 'OutcomeAnalysisCIUpperLimitComment', 'OutcomeAnalysisDispersionType', 'OutcomeAnalysisDispersionValue', 'OutcomeAnalysisEstimateComment', 'OutcomeAnalysisGroupDescription', 'OutcomeAnalysisGroupId', 'OutcomeAnalysisNonInferiorityComment', 'OutcomeAnalysisNonInferiorityType', 'OutcomeAnalysisOtherAnalysisDescription', 'OutcomeAnalysisPValue', 'OutcomeAnalysisPValueComment', 'OutcomeAnalysisParamType', 'OutcomeAnalysisParamValue', 'OutcomeAnalysisStatisticalComment', 'OutcomeAnalysisStatisticalMethod', 'OutcomeAnalysisTestedNonInferiority', 'OutcomeCategoryTitle', 'OutcomeClassDenomCountGroupId', 'OutcomeClassDenomCountValue', 'OutcomeClassDenomUnits', 'OutcomeClassTitle', 'OutcomeDenomCountGroupId', 'OutcomeDenomCountValue', 'OutcomeDenomUnits', 'OutcomeGroupDescription', 'OutcomeGroupId', 'OutcomeGroupTitle', 'OutcomeMeasureAnticipatedPostingDate', 'OutcomeMeasureCalculatePct', 'OutcomeMeasureDenomUnitsSelected', 'OutcomeMeasureDescription', 'OutcomeMeasureDispersionType', 'OutcomeMeasureParamType', 'OutcomeMeasurePopulationDescription', 'OutcomeMeasureReportingStatus', 'OutcomeMeasureTimeFrame', 'OutcomeMeasureTitle', 'OutcomeMeasureType', 'OutcomeMeasureTypeUnitsAnalyzed', 'OutcomeMeasureUnitOfMeasure', 'OutcomeMeasurementComment', 'OutcomeMeasurementGroupId', 'OutcomeMeasurementLowerLimit', 'OutcomeMeasurementSpread', 'OutcomeMeasurementUpperLimit', 'OutcomeMeasurementValue', 'OverallOfficialAffiliation', 'OverallOfficialName', 'OverallOfficialRole', 'OverallStatus', 'OversightHasDMC', 'PatientRegistry', 'Phase', 'PointOfContactEMail', 'PointOfContactOrganization', 'PointOfContactPhone', 'PointOfContactPhoneExt', 'PointOfContactTitle', 'PrimaryCompletionDate', 'PrimaryCompletionDateType', 'PrimaryOutcomeDescription', 'PrimaryOutcomeMeasure', 'PrimaryOutcomeTimeFrame', 'ReferenceCitation', 'ReferencePMID', 'ReferenceType', 'RemovedCountry', 'ResponsiblePartyInvestigatorAffiliation', 'ResponsiblePartyInvestigatorFullName', 'ResponsiblePartyInvestigatorTitle', 'ResponsiblePartyOldNameTitle', 'ResponsiblePartyOldOrganization', 'ResponsiblePartyType', 'ResultsFirstPostDate', 'ResultsFirstPostDateType', 'ResultsFirstPostedQCCommentsDate', 'ResultsFirstPostedQCCommentsDateType', 'ResultsFirstSubmitDate', 'ResultsFirstSubmitQCDate', 'RetractionPMID', 'RetractionSource', 'SamplingMethod', 'SecondaryId', 'SecondaryIdDomain', 'SecondaryIdLink', 'SecondaryIdType', 'SecondaryOutcomeDescription', 'SecondaryOutcomeMeasure', 'SecondaryOutcomeTimeFrame', 'SeeAlsoLinkLabel', 'SeeAlsoLinkURL', 'SeriousEventAssessmentType', 'SeriousEventNotes', 'SeriousEventOrganSystem', 'SeriousEventSourceVocabulary', 'SeriousEventStatsGroupId', 'SeriousEventStatsNumAffected', 'SeriousEventStatsNumAtRisk', 'SeriousEventStatsNumEvents', 'SeriousEventTerm', 'StartDate', 'StartDateType', 'StatusVerifiedDate', 'StdAge', 'StudyFirstPostDate', 'StudyFirstPostDateType', 'StudyFirstSubmitDate', 'StudyFirstSubmitQCDate', 'StudyPopulation', 'StudyType', 'SubmissionMCPReleaseN', 'SubmissionReleaseDate', 'SubmissionResetDate', 'SubmissionUnreleaseDate', 'TargetDuration', 'UnpostedEventDate', 'UnpostedEventType', 'UnpostedResponsibleParty', 'VersionHolder', 'WhyStopped']\n",
      "328 fields in total\n",
      "2023-10-19 21:08:53 - End\n"
     ]
    }
   ],
   "source": [
    "print(f\"{dt.now().strftime('%Y-%m-%d %H:%M:%S')} - Start\")\n",
    "all_study_fields_url =\"https://classic.clinicaltrials.gov/api/info/study_fields_list\"\n",
    "response = requests.get(all_study_fields_url)\n",
    "all_study_fields_xml  = response.text\n",
    "\n",
    "# Parse the XML data\n",
    "root = ET.fromstring(all_study_fields_xml)\n",
    "\n",
    "# Find all Field elements within FieldList\n",
    "field_elements = root.findall(\".//FieldList/Field\")\n",
    "\n",
    "# Extract the Field Name attribute and store in a list\n",
    "all_study_fields = [str(field.get(\"Name\")) for field in field_elements]\n",
    "\n",
    "# Print the list of field names\n",
    "print(all_study_fields)\n",
    "print(f\"{len(all_study_fields)} fields in total\")\n",
    "print(f\"{dt.now().strftime('%Y-%m-%d %H:%M:%S')} - End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative scan per json into a dataframe\n",
    "After we download over 10GB of data, we can parse it into a csv file/sql database or anything similar that we can then use in downstream calculations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "\n",
    "# Create an empty list to store the data records\n",
    "data_records = []\n",
    "max_studies = 10000000 # <-- set to a smaller number for testing. There are less than 0.5m studies in total as of Oct 2023\n",
    "n_write = 100000 # write to database every n_write records, larger values are faster but use more memory.\n",
    "# selected_study_fields = ['NCTId', 'Condition', 'BriefTitle'] # <-- smaller set of fields for testing\n",
    "selected_study_fields = all_study_fields\n",
    "\n",
    "\n",
    "# Specify the top-level folder path containing subfolders with JSON files\n",
    "folder_path = '../data/AllAPIJSON/'\n",
    "\n",
    "rebuild_db = True # <-- set to True to rebuild the database from scratch\n",
    "only_add_new_records = True # <-- set to True to add new records to the database instead of rebuilding all records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some potetnially useful functions\n",
    "\n",
    "\n",
    "\n",
    "def convert_lists_to_strings(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert list values in a DataFrame to strings.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input DataFrame containing columns with list values.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with list values converted to strings.\n",
    "    \"\"\"\n",
    "    # Iterate over the DataFrame's columns\n",
    "    for col in df.columns:\n",
    "        # Check if the column contains lists\n",
    "        if df[col].apply(lambda x: isinstance(x, list)).any():\n",
    "            # Convert lists to strings\n",
    "            df[col] = df[col].astype(str)\n",
    "    return df\n",
    "\n",
    "def extract_field(data: Any, field_name: str) -> Any:\n",
    "    \"\"\"\n",
    "    Extract a specific field value from nested dictionaries or lists within data.\n",
    "\n",
    "    Parameters:\n",
    "    data (dict or list): The data structure to search for the field.\n",
    "    field_name (str): The name of the field to extract.\n",
    "\n",
    "    Returns:\n",
    "    Any: The extracted field value or None if not found.\n",
    "    \"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        if field_name in data:\n",
    "            return data[field_name]\n",
    "        else:\n",
    "            for key, value in data.items():\n",
    "                result = extract_field(value, field_name)\n",
    "                if result is not None:\n",
    "                    return result\n",
    "    elif isinstance(data, list):\n",
    "        for item in data:\n",
    "            result = extract_field(item, field_name)\n",
    "            if result is not None:\n",
    "                return result\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-19 21:09:27 - Rebuilding database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 611/611 [3:44:26<00:00, 22.04s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-20 00:54:53 - Finished rebuilding database\n"
     ]
    }
   ],
   "source": [
    "if rebuild_db:\n",
    "    table_name = 'alltrials' # In inital run I was not sure what goes into the 'table_name' and was putting the path '../data/alltrials' instead of just 'alltrials'. \n",
    "    print(f\"{dt.now().strftime('%Y-%m-%d %H:%M:%S')} - Rebuilding database\")\n",
    "    conn = sqlite3.connect('../data/alltrials.db')  \n",
    "    existing_nctids = set()  # Create a set to store existing NCTIDs\n",
    "\n",
    "    if only_add_new_records:\n",
    "        \n",
    "        # Load existing NCTIDs from the SQL database\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(f\"SELECT NCTid FROM '{table_name}' \")\n",
    "        existing_nctids.update(row[0] for row in cursor.fetchall())\n",
    "\n",
    "    i = 0 # Counter for files processed\n",
    "    for subfolder_name in tqdm(os.listdir(folder_path)):\n",
    "        subfolder_path = os.path.join(folder_path, subfolder_name)\n",
    "\n",
    "        # Check if the item in the top folder is a directory (subfolder)\n",
    "        if os.path.isdir(subfolder_path):    \n",
    "            for filename in os.listdir(subfolder_path):\n",
    "                if i > max_studies:\n",
    "                    break\n",
    "                if filename.endswith('.json'):\n",
    "                    i+=1\n",
    "                    nctid = filename.replace('.json', '')  # Extract NCTid from filename\n",
    "                    if only_add_new_records and nctid in existing_nctids:\n",
    "                        continue\n",
    "                    else:\n",
    "                        file_path = os.path.join(subfolder_path, filename)\n",
    "\n",
    "                        # Read JSON data\n",
    "                        with open(file_path, 'r') as json_file:\n",
    "                            study_data = json.load(json_file)\n",
    "                            row_data = [extract_field(study_data, field) for field in selected_study_fields]\n",
    "                            data_records.append(row_data)\n",
    "                if (i % n_write == 0): # save every n_write records and empty the list\n",
    "                    df = pd.DataFrame(data_records)\n",
    "                    df = convert_lists_to_strings(df)\n",
    "                    df.columns = selected_study_fields\n",
    "                    \n",
    "                    df.to_csv('../data/alltrials.csv', mode='a', header=True, sep=\"\\t\")\n",
    "                    df.to_sql(table_name, conn, if_exists='append', index=False)\n",
    "                    data_records = []    \n",
    "    # Final write of the remaining data after the loop\n",
    "    if len(data_records) > 0:\n",
    "        df = pd.DataFrame(data_records)\n",
    "        df = convert_lists_to_strings(df)\n",
    "        df.columns = selected_study_fields\n",
    "        df.to_csv('../data/alltrials.csv', mode='a', header=True, sep=\"\\t\")\n",
    "        df.to_sql(table_name, conn, if_exists='append', index=False)\n",
    "    print(f\"{dt.now().strftime('%Y-%m-%d %H:%M:%S')} - Finished rebuilding database\")   \n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wespy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
